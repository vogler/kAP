\documentclass{scrartcl}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage[pdftex]{hyperref}
\usepackage{float}
\usepackage[pdftex]{graphicx}
\DeclareGraphicsExtensions{.pdf, .png, .jpg}
\usepackage{color}
\usepackage{tikz}
\usepackage{graphicx}

\newcommand{\red}[1]{{\color{red} #1}}

% Command for inserting a todo item
\newcommand{\todo}[1]{%
% Add to todo list
\addcontentsline{tdo}{todo}{\protect{#1}}%
%
\begin{tikzpicture}[remember picture, baseline=-0.75ex]%
\node [coordinate] (inText) {};
\end{tikzpicture}%
%
% Make the margin par
\marginpar{%
\begin{tikzpicture}[remember picture]%
\definecolor{orange}{rgb}{1,0.5,0}
\draw node[draw=black, fill=orange, text width = 2.5cm] (inNote)
{#1};%
\end{tikzpicture}%
}%
%
\begin{tikzpicture}[remember picture, overlay]%
\draw[draw = orange, thick]
([yshift=-0.2cm] inText)
-| ([xshift=-0.3cm] inNote.west)
-| (inNote.west);
\end{tikzpicture}%
%
}%

\newcommand{\graphic}[3][width=\linewidth] % options, label/filename, caption
{
  \begin{figure}[h!t]
    \centering
    \includegraphics[#1]{img/#2}
    \caption{#3}
    \label{fig:#2}
  \end{figure}
}
\newcommand{\refFigure}[1]{figure \ref{fig:#1}}

\title{Visualization of 3D Gamma Probe Data on a Mobile Device}
\author{Johannes Merkle \\ Ralf Vogler}
%\institute{Technische Universit\"at M\"unchen\\
%\email{merkle@in.tum.de \hspace vogler@in.tum.de}}

%\def\imgsize{3in}

\begin{document}
\maketitle
%\tableofcontents


\begin{abstract}
The usability of a system is an important factor of its success, especially if the system is used in a complex environment like the operating room. Therefore there has been a lot of research and many new developments in this field recently, like tracked probes in freehand SPECT systems. In this paper we present an approach that further improves the usability of such a system by attaching a handheld device to the probe in order to avoid issues with hand-eye coordination of the user. The approach is then evaluated in a short usability user study.
\end{abstract}



\section{Introduction}


\subsection{Usability for medical devices}
%\red{IPCAI11Usability zusammenfassen, usability erkl�ren, verweis auf declipsespect und brainlabding}
The goal of usability engineering is to make a product more efficient to use, easier to learn and more satisfying for the user.

Since medical devices are typically safety-critical, they must meet specific requirements for usability. Besides the usability factors effectiveness, efficiency and satisfaction, they must also be safe. The software has to be intuitive, stable and easy to use. Before it can be used in the operating room a usability test in a special usability lab should be performed in order to simulate a typical user environment and situation \cite{bigdelou}.
%\paragraph*{Usability in Bezug auf declipseSPECT und Brainlab-Ding}


\subsection{Sentinel lymph node biopsy}
%\red{slnb beschreiben Wendler2010EurJNuclMedMolImaging}\\
% http://www.cancer.gov/cancertopics/factsheet/detection/sentinel-node-biopsy
% http://www.bupa.co.uk/individuals/health-information/directory/s/slnb
The main use case for the declipseSPECT system (see section \ref{dspect}) is sentinel lymph node biopsy (SLNB). Sentinel lymph nodes are the lymph nodes to which cancer cells are most likely to spread from a primary tumor. Lymph nodes are part of the body's lymphatic system which is shown in \refFigure{lymphatic-system}. Many types of cancer spread through the lymphatic system and the earliest sites of spread are nearby lymph nodes, which are also called sentinel lymph nodes.
The procedure of a SLNB is shown in \refFigure{slnb}. A SLNB is usually done at the same time the primary tumor is removed but it can also be done before or after.
\graphic[scale=.7]{lymphatic-system}{The lymphatic system \cite{bupa}}
\graphic[scale=.7]{slnb}{Sentinel lymph node biopsy of the breast \cite{cancer}}


\subsection{declipseSPECT - a freehand SPECT system}
\label{dspect}
%Navab2008ISBINavigatedProbeOverview
%Wendler2007MICCAIRecon
%Wendler2010EurJNuclMedMolImaging
%http://www.surgiceye.com/index.php?option=com_content&view=article&id=60&Itemid=66
\paragraph*{Usage}
The declipseSPECT system is a freehand SPECT system, which means that radioactive tracers are injected into the patient and the radiation is measured with a gamma probe. The advantage of declipseSPECT is that it tracks the patient and the probe and can compute a 3D reconstruction of the radiation \cite{wendler}.
Freehand SPECT systems are mainly used for lymphatic mapping in sentinel lymph node biopsy, especially for breast cancer \cite{buck}. Intra-operative 3D imaging has many clinical benefits: it allows for localization of SLN and minimally invasive access, less training effort (the procedure is very complex without visualization), quality control and automated documentation. This results in less morbidity, a shortened operation length and therefore reduced procedure costs \cite{surgiceye}.
\paragraph*{Setup}
The system combines a handheld 1D-gammaprobe with a camera tracking system. The tracking system tracks both the patient and the probe which have retro-reflective markers attached to them. This way, the position and angle of the probe in relation to the patient is known at all times (given that the markers aren't occluded). When using the probe to measure the radioactivity of a tracer in the region of interest, the position, angle and measurements of the probe are collected. Based on this data, a 3D reconstruction of the measured radiation can be computed.
This data can then be used to augment the video stream from the tracking cameras' position (camera view). Another option is to show a virtual image from the probe's position (3D view).
The system consists of the tracked probe, a tracking marker on the patient and a terminal that holds the cameras (two infrared for tracking, one video) and has a touch-screen attached to it, which is used for both the visualization and user input. The declipseSPECT stationary system is shown in \refFigure{declipseSPECT} and \refFigure{declipseSPECT-OR} shows how it is used in the operating room.
\graphic[scale=.7]{declipseSPECT}{declipseSPECT stationary system \cite{surgiceye}}
\graphic[scale=.7]{declipseSPECT-OR}{declipseSPECT in the operating room \cite{surgiceye}}


\subsection{Usability problem: hand-eye-coordination between probe and display}
%skizze/bild
%problematik erkl�ren und veranschaulichen
When using the the declipseSPECT system, the surgeon needs to look at the screen to be able to see the radioactive hotspots. At the same time he needs to see the patient to properly navigate the probe. This could lead to difficulties because he either needs to continuously switch between looking at the patient and the screen or try to navigate the probe while looking at the screen, which shows the scenery from the tracking cameras' point of view, which might lead to issues with hand-eye coordination. An example is shown in \refFigure{declipseSPECT-OR}.
In this paper we introduce an addition to the declipseSPECT system that tries to solve this problem.


\subsection{Approach}
Our approach is to visualize the important data from the terminal screen on a screen attached to the probe, so the data is always in the surgeon's field of view. In order to be properly integrated into the system, the screen mustn't be too big and needs to be attached to the probe in a way that doesn't obstruct the work of the surgeon. Due to these constraints we only show a select part of the data. We show a view similar to the 3D view on the terminal screen, i.e. the probe's point of view. It shows the hotspots of radioactivity as spheres of different color, depending on their intensity. In addition we display the distance to the nearest radioactive hotspot, the currently measured radiation (counts per second) and a histogram of the previously measured radiation.



\section{Implementation}

\subsection{Overview}
%Hardware: iPod Touch 4G\\
%Development environment: Objective C in Xcode, C++ in Visual Studio\\
%Libraries: GoogleData for XML-processing\\
%Visualization: OpenGL ES 1.1 (without vertex and fragment shaders)\\
%\red{(OpenGL basics, transformation matrices etc.)\\
%(lighting modes)}\\
%Data exchange: XML from HTTP-Server in existing software\\
We used an iPod Touch 4G which we attached to the probe (see \refFigure{probe}) in order to display the most important data of the existing software.
The iPod Touch was chosen because it is relatively cheap, has good hardware and a good development environment. Furthermore it has the right size for attachment on the probe and it also has a built-in camera. We originally planned to use the camera's image as a background of the application which however proved impractically because of calibration and because the display couldn't be attached in a way that one could see the content and it wouldn't occlude the markers.

Most of the development was done in Objective C in Xcode for the software on the iPod and C++ in Visual Studio for the software on the server.

Communication between the iPod (client) and the declipseSPECT software (server) works via WIFI which means that there aren't any additional cables and the display can simply be attached to the probe when needed. The connection parameters can be modified in the settings page of the application.
An overview of the communication is shown in \refFigure{sequence-diagram}. It is important to note that the data is retrieved in its own loop. The OpenGL view, which is behind the other UI elements, is set up first and a timer for \verb|loadValuesFromXML| is started. After this the loop for drawing the content starts, i.e. \verb|drawView| is constantly called. The timer executes \verb|loadValuesFromXML| in a certain interval (currently 20Hz) which loads the current values from the server, parses the XML and updates the UI. The spheres which visualize the radioactive hotspots are created and stored in a list which is then read during \verb|drawView|.
\graphic[scale=.8]{sequence-diagram}{Sequence diagram}


\subsection{Design}
The UI of the existing system running on the touchscreen computer is shown in \refFigure{server2}.
A mock-up of the interface for our application is shown in \refFigure{mockup} and the final version of the UI in \refFigure{screen-annotated}. Elements like the distance to the nearest hotspot and the cross-hair were recommended during evaluation and added afterwards.
\graphic[scale=.43]{server2}{User interface of the existing system}
\graphic[scale=.5]{mockup}{Mock-up of the user interface}
\graphic[scale=.5]{screen-annotated}{Final version of the user interface with annotations}


\subsection{Integration with the existing software}
An example for the transmitted XML is shown in \refFigure{data}. The client currently requests this data 20 times per second (enough for fluid visualization) and the server responds with the current values each time. The system has been successfully tested with up to 50Hz, which didn't show any noticable performance impact on the client nor the server.
For XML-processing on iOS the GoogleData library was used which provides a more convenient wrapper around NSXML which also supports XPath.
The part on the server uses Qt \cite{qt} and Eigen \cite{eigen} for matrices. The server also modifies the camera matrix because OpenGL uses a different coordinate system and expects a transposed matrix which is shown below:
\begin{verbatim}
// get the transformation of the probe in voi coordinates
Eigen::Matrix4d trans = m_probe->getTransformationInOtherCS(m_trackedVolumeImage);				
Eigen::Matrix4d camera2gl;
camera2gl <<  1, 0, 0, 0,
              0, -1, 0, 0,
              0, 0, -1, 0,
              0, 0, 0, 1;
trans = camera2gl * trans.inverse();
Eigen::Matrix4d transT = trans.transpose();
\end{verbatim}
\graphic[scale=.5]{data}{Example for XML-data with annotations}


\subsection{Visualization of data}
Visualization was done using OpenGL ES 1.1 which runs on all generations of the iPod Touch. OpenGL ES 2.0 uses vertex and fragment shaders but needs a certain version of iOS and only works on 3rd generation and newer.
Since there is no framework like GLUT, the spheres had to be drawn manually. To initialize a sphere the function \verb|initSolidSphere| gets arrays in which the computed vertices of triangle fans and triangle strips will be stored, the radius of the sphere and how many stacks (horizontal) and slices (vertical) should be used.
The difference between fans and strips is shown in \refFigure{sphere}.

The signature of the function looks as follows:
\begin{verbatim}
initSolidSphere(Vertex3D **triangleStripVertexHandle,
    Vector3D **triangleStripNormalHandle,
    GLuint *triangleStripVertexCount,
    Vertex3D **triangleFanVertexHandle,
    Vector3D **triangleFanNormalHandle,
    GLuint *triangleFanVertexCount,
    GLfloat radius,
    GLuint slices, GLuint stacks)
\end{verbatim}
\graphic[scale=.5]{sphere}{Wireframe sphere and its constituents \cite{wikipedia}}



\section{Tests}
\paragraph*{Setup}
The iPod touch had to be fixated on the probe, for which we used Velcro strips (see \refFigure{probe}). Since there are no cables, it can be easily removed if the additional display isn't needed.
\graphic[scale=.5]{probe}{Attachment of the iPod to the probe}

For the usability evaluation we selected persons familiar with the declipseSPECT environment and let them use the system. We gave a task to be done using the modified declipseSPECT system and asked them afterwards to fill out an evaluation questionnaire.
The task was to focus all radioactive hotspots in a set of prerecorded demo data not using the terminal screen but only the screen attached to the probe. Additionally the slider was to be used to set a suitable sphere size to properly display the data. The evaluation was done using the SUS \cite{sus} questionnaire and additional questions which were more specific to the system. The additional questions were not used for determining the SUS score.
The result of the evaluation was generally positive with an average SUS score of 79.16 out of 100 points. The additional questions indicated that the way the iPod is attached to the probe could be improved.



\section{Conclusion}
The evaluation indicated that the usability compared to the previous system could be improved. The feedback was generally positive, especially the intuitive handling and visualization.
Further challenges would be the introduction in the operating room which requires everything to be sterile (extra enclosing could make the display too bulky or the touch screen unresponsive), stable and self explanatory.
The attachment of the display using Velcro strips is practical but it doesn't allow the angle to be adjusted. On the other hand, if the angle is adjustable, the display might be problematic for marker detection or make the probe inconvenient to hold.
On top, all this should be evaluated by medical personnel that know what is important in such a system.


\bibliographystyle{unsrt}
\bibliography{ausarbeitung}

\end{document}